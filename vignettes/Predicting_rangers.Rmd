---
title: "Predicting the number of rangers"
output:
  rmarkdown::html_document:
    df_print: paged
    toc: true
    toc_depth: 4
    code_folding: hide
vignette: >
  %\VignetteIndexEntry{Number_rangers}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  chunk_output_type: console
---

<style type="text/css">
  .main-container {
    max-width: 1200px;
    margin-left: auto;
    margin-right: auto;
  }
</style>

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  error = TRUE,
  comment = "#>",
  cache = FALSE, # don't put TRUE as inline chunk make R CMD check to crash
  cache.path = "cache/cache_vignette_predicting_rangers/",
  fig.path = "figs/fig_vignette_predicting_rangers/",
  fig.align = 'center'
)
```

```{r setup, message=FALSE}
library(rangeR)
library(dplyr)
library(tidyr)
library(ggplot2)
library(broom)
library(gt)
library(spaMM)
library(rnaturalearth)
```

## Using only the total area of terrestrial PAs in the country as predictor

At the level of countries, the *total area of terrestrial PAs in the country* (**PA_area** for short) is a very good predictor for the number of rangers (**staff_rangers** for short).
I will first characterise the relationship between PA_area and staff_rangers before using it to predict the number of rangers in countries for which we don't have it.

### Data preparation

We first need to modify a little bit our data.

```{r data prep, warning=FALSE}
rm(data_rangers) # delete existing one if any, to make sure we use the one of the package

## for private analysis only, TODO: remove before release
data_rangers$countryname_iso[data_rangers$countryname_eng == "W African Country"] <- "SEN"

data_rangers %>%
  mutate(PA_area = if_else(!is.na(area_PA_total), area_PA_total, area_PA_WDPA)) -> data_rangers_clean

## Adding latitude and longitude
world_sf <- ne_countries(scale = "large", returnclass = "sf")
world_sf$iso_a3_eh[world_sf$admin == "Norway"] <- "NOR"
#world_sf$admin[unlist(sapply(world_sf$admin, function(x) grepl("Gu.*", x)))] ## to search for typos

world_sf$center <- sf::st_centroid(world_sf$geometry, of_largest_polygon = TRUE)
data_rangers_clean %>%
  left_join(world_sf %>% select(center, iso_a3_eh), by = c("countryname_iso" = "iso_a3_eh")) -> data_rangers_clean

data_rangers_clean %>%
  unnest_wider(center) %>%
  rename(long = `...1`, lat = `...2`) -> data_rangers_clean

## Adding flags
data_rangers_clean %>%
  mutate(flag = countrycode::countrycode(sourcevar = countryname_iso, "iso3c", "unicode.symbol"),
         country = paste(countryname_eng, flag)) -> data_rangers_clean

## Adding row names
rownames(data_rangers_clean) <- data_rangers_clean$countryname_iso
```

Here is the dataset we are using below:

```{r data}
data_rangers_clean
```

We will also use a version of this dataset without Greenland in same cases since this country is a clear outlier.

```{r data_no_greenland, warning=FALSE}
data_rangers_clean %>%
  filter(countryname_eng != "Greenland") -> data_rangers_clean_noG

rownames(data_rangers_clean_noG) <- data_rangers_clean_noG$countryname_iso
```

### Relationship between PA_area and staff_rangers

On the original scale, the relationship is not very obvious:

```{r area_PA_total plot1, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean) +
  aes(y = staff_rangers, x = PA_area, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

but when plotting the variable on a log scale, the relation appears more clearly:

```{r area_PA_total plot2, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean) +
  aes(y = staff_rangers, x = PA_area, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  coord_trans(x = "log", y = "log1p") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(1, 1e7)) +
  scale_y_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

**That the relationship is (roughly) linear on a log-log plot, suggests an allometric relationship and not a proportional relationship**.

Let's start by showing what is wrong about assuming that the relationship is proportional:

```{r area_PA_total plot3, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = PA_area / staff_rangers, x = PA_area, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  coord_trans(x = "log", y = "log1p") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(1, 1e7)) +
  scale_y_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

As you can see in the previous plot, the area of PA per ranger increases sharply with PA_area. So we cannot say that one ranger covers a fixed given area. For the same reason, we cannot say that there is x rangers per square-km of PAs.

In contrast, owing to the particular nature of the allometric relationship we have (more on that later), what is fixed is the ratio of the log quantities:

```{r area_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = PA_area, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(1, 1e7)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

As you can see, the ratio of the log no longer depend on PA_area.
(In case you wonder, the $+1$ is there so that to avoid log(0) which are not defined).

### Fitting the allometric relationship

An interesting observation is that the ratio between the logs is approximatively normally distributed. Here is the QQ plot:

```{r gaussian, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(sample = log(staff_rangers + 1) / log(PA_area)) +
  geom_qq(colour = "blue") + 
  geom_qq_line() +
  theme_minimal()
```

The mean of such normal distribution is estimated to `r round(mean(log(data_rangers_clean_noG$staff_rangers + 1) / log(data_rangers_clean_noG$PA_area), na.rm = TRUE), digits = 3)` and its SD to `r round(sd(log(data_rangers_clean_noG$staff_rangers + 1) / log(data_rangers_clean_noG$PA_area), na.rm = TRUE), digits = 3)`.

Therefore, this very crude computation (hereafter called ad-hoc) suggests that:

$\large{\mathrm{staff\_rangers} + 1 = \mathrm{PA\_area}^{`r round(mean(log(data_rangers_clean_noG$staff_rangers + 1) / log(data_rangers_clean_noG$PA_area), na.rm = TRUE), digits = 3)`}}$.

That the coefficient of allometry is positive implies that staff_rangers increases with PA_area.

That the coefficient of allometry is lower than 1 implies that *the increase in staff_rangers with PA_area* decreases with PA_area

(Note to self: a non linear maximum likelihood fit gives very similar results.)
```{r nlm, warning=FALSE, cache=TRUE}
my_logLik <- function(par, data, scale = -1) {
  coef <- par[1]
  sd <- par[2]
  scale * sum(dnorm(log(data$staff_rangers + 1)/log(data$PA_area) - coef, mean = 0, sd = sd, log = TRUE), na.rm = TRUE)
  }

set.seed(1)
optim(c(0, 0.1), fn = my_logLik, data = data_rangers_clean_noG)
```


To get more formal, let's fit the allometric relationship using a linear model:

$\mathrm{log}(\mathrm{staff\_rangers} + 1) = a \times \mathrm{log}(\mathrm{PA\_area}) + b$ (model 1).

Here are the estimates we obtain:

```{r lm}
fit_allometry <- lm(log(staff_rangers + 1) ~  log(PA_area), data = data_rangers_clean_noG)
tidy(summary(fit_allometry)) %>%
  mutate(across(where(is.numeric), .fns = round, digits = 3)) %>%
  gt()
```

as you can see, the intercept ($b$) is no different from 0, so we can simplify the model to:

$\mathrm{log}(\mathrm{staff\_rangers} + 1) = a \times \mathrm{log}(\mathrm{PA\_area})$ (model 2).

This leads to the following estimates:

```{r lm2}
fit_allometry2 <- lm(log(staff_rangers + 1) ~  log(PA_area) - 1, data = data_rangers_clean_noG)
tidy(summary(fit_allometry2)) %>%
  mutate(across(where(is.numeric), .fns = round, digits = 3)) %>%
  gt()
```

Dropping the intercept is more rigorously justified by the fact that doing so improves the predictive ability of the model (AIC model 1 = `r round(AIC(fit_allometry), digits = 1)`; AIC model 2 = `r round(AIC(fit_allometry2), digits = 1)`).

Fitting simple LM thus confirms that we do not need to consider an intercept and it leads a relationship virtually identical to the one we established earlier:

$\large{\mathrm{staff\_rangers} + 1 = \mathrm{PA\_area}^{`r round(coef(fit_allometry2)[[1]], digits = 3)`}}$.

This simple linear models meets well the assumptions of linear regressions (homoscedasticity, independence and normality):

```{r plot lm fit, fig.height=10, fig.width=10, cache=TRUE}
par(mfrow = c(2, 2))
plot(fit_allometry2)
```

Another way of fitting an linear model is to directly fit the ratio: 

$\dfrac{\mathrm{log}(\mathrm{staff\_rangers} + 1)}{\mathrm{log}(\mathrm{PA\_area})} = a$ (model 3).

```{r lm3}
fit_allometry3 <- lm(log(staff_rangers + 1)/log(PA_area) ~ 1, data = data_rangers_clean_noG)
tidy(summary(fit_allometry3)) %>%
  mutate(across(where(is.numeric), .fns = round, digits = 3)) %>%
  gt()
```

This retrieves exactly the same coefficient of allometry than the first ad-hoc method (note to self: perfect equivalence in REML but here also true in ML) and the model fit is also very good:

```{r plot lm fit3, fig.height=10, fig.width=10, cache=TRUE}
par(mfrow = c(2, 2))
plot(fit_allometry3)
```
Note that there is only one fitted value is this model, which makes sense, but leads to strange plots above.

The model 2 & 3 are not strictly equivalent because they impose different structure in terms of the residual variation.

This is because if

$Y/X = \beta_0 + \mathrm{homoscedastic\ residuals}$

then

$Y = \beta_0 \times X + X \times \mathrm{homoscedastic\ residuals}$

or

$Y = \beta_0 \times X + \mathrm{heteroscedastic\ residuals}$

So we can use this result to rewrite the model 3 under a form that is comparable to model 2.
This is a little technical, but the results show that model 2 is better at fitting the data than model 3.
Furthermore, since model 3 produces a coefficient of allometry identical to the one produced by the ad-hoc method we first introduced, the fit of model 2 is thus also better than the ad-hoc model. 
In short, we have good reasons for model 2 to be our base model.

```{r comparing models}
fit_model2 <- fitme(I(log(staff_rangers + 1)/log(PA_area)) ~ 1, data = data_rangers_clean_noG)
fit_model3 <- fitme(I(log(staff_rangers + 1)/log(PA_area)) ~ 1, prior.weights = sqrt(1/log(PA_area)), data = data_rangers_clean_noG)
AIC(fit_model2)
AIC(fit_model3)
```

Let's now visualise the fit of model 2 on the raw data:

```{r area_PA_total with PI plot2, fig.height=6, fig.width=6, cache=TRUE}
x <- 10^(seq(0, 7, length = 1000))
pred_for_plot <- as.data.frame(predict(fit_allometry2, newdata = data.frame(PA_area = x), interval = "prediction"))
pred_for_plot$PA_area <- x

CI_for_plot <- as.data.frame(predict(fit_allometry2, newdata = data.frame(PA_area = x), interval = "confidence"))
CI_for_plot$PA_area <- x

ggplot(data_rangers_clean) +
  aes(y = staff_rangers, x = PA_area, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  geom_line(aes(y = exp(fit) - 1, x = PA_area), data = pred_for_plot, inherit.aes = FALSE) +
  geom_line(aes(y = exp(upr) - 1, x = PA_area), data = pred_for_plot, inherit.aes = FALSE, linetype = "dashed") +
  geom_line(aes(y = exp(lwr) - 1, x = PA_area), data = pred_for_plot, inherit.aes = FALSE, linetype = "dashed") +
  geom_line(aes(y = exp(upr) - 1, x = PA_area), data = CI_for_plot, inherit.aes = FALSE, linetype = 6) +
  geom_line(aes(y = exp(lwr) - 1, x = PA_area), data = CI_for_plot, inherit.aes = FALSE, linetype = 4) +
  coord_trans(x = "log1p", y = "log1p") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(0, 1e7)) +
  scale_y_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(0, 1e5)) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

The larger interval is the 95% prediction interval (i.e. where new data may be) and the small one the 95% confidence interval (i.e. where true relationship may be).


### Predictive power

We now turn to the predictive power (on the fitted data). So far, so good:

```{r plot lm pred, fig.height=6, fig.width=6, cache=TRUE}
data_rangers_clean_noG %>%
  mutate(predicted_rangers = data_rangers_clean_noG$PA_area^coef(fit_allometry2)[[1]] - 1,
         observed_rangers = data_rangers_clean_noG$staff_rangers) -> data_rangers_clean_noG2

data_rangers_clean_noG2 %>%
  filter(!is.na(observed_rangers)) -> data_rangers_clean_noG2_obs

data_rangers_clean_noG2 %>%
  filter(is.na(observed_rangers)) -> data_rangers_clean_noG2_notobs


ggplot(data_rangers_clean_noG2_obs) +
  aes(y = observed_rangers, x = predicted_rangers, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  geom_abline(slope = 1) +
  coord_trans(x = "log1p", y = "log1p") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(1, 1e5)) +
  scale_y_continuous(breaks = 10^(0:7), minor_breaks = NULL, limits = c(1, 1e5)) +
  labs(y = "Observed staff_rangers", x = "Predicted staff_rangers") +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

The Pearson correlation between the predicted and the observed `log(staff_rangers + 1)` is actually pretty high: r = `r round(cor(log(data_rangers_clean_noG2_obs$predicted_rangers + 1), log(data_rangers_clean_noG2_obs$observed_rangers + 1)), digits = 2)`.

This is good, very good, but also a little misleading since being a little off on a log scale can mean a lot.

The Pearson correlation between the predicted and the observed number of rangers (not logged) is lower due to the non-linearity: r = `r round(cor(data_rangers_clean_noG2_obs$predicted_rangers, data_rangers_clean_noG2_obs$observed_rangers), digits = 2)`.
A non-parametric correlation retrieves a high value: rho (Spearman) = `r round(cor(data_rangers_clean_noG2_obs$predicted_rangers, data_rangers_clean_noG2_obs$observed_rangers, method = "spearman"), digits = 2)`.

Another way to look at the predictive power on the original scale is to compute the sum of rangers for the country for which we know it and compare that to the observations (nb: those numbers do not include Greenland):

```{r predictive sum}
gt(tibble(total_predicted = sum(data_rangers_clean_noG2_obs$predicted_rangers),
          total_observed = sum(data_rangers_clean_noG2_obs$observed_rangers)))
```

That means that we predict `r round(100* sum(data_rangers_clean_noG2_obs$predicted_rangers) /  sum(data_rangers_clean_noG2_obs$observed_rangers), digits = 1)` % of the observed sum.
The reason why it is a little lower is that the prediction underestimate the countries with the largest number of rangers. For example, in India alone, the model predicts `r round(data_rangers_clean_noG2_obs[data_rangers_clean_noG2_obs$countryname_iso == "IND", "predicted_rangers", drop = TRUE])` instead of `r format(data_rangers_clean_noG2_obs[data_rangers_clean_noG2_obs$countryname_iso == "IND", "staff_rangers", drop = TRUE], scientific = FALSE)`.

So, is this model good or not? The result on the sum is quite scary, but this is because I did not yet consider the uncertainty on the predictions. In particular, I used the same value for the coefficient of allometry for predicting all countries, but I did show you above that there is quite a lot of uncertainty around this coefficient. For example, on the real data, India does not have a ratio of `r round(coef(fit_allometry3)[[1]], digits = 3)` but of `r round(data_rangers_clean %>% filter(countryname_iso == "IND") %>% mutate(ratio = log(staff_rangers + 1)/log(PA_area)) %>% pull(ratio), digits = 3)`, which is quite different!

### Predictions

There many ways to compute predictions and we will perform several of them.

Before we do so however, it is important to check where countries with no rangers information are compared to countries with information in view of PA_area:

```{r PA_area explo, fig.height=6, fig.width=6, cache=TRUE}
data_rangers_clean %>%
  mutate(rangers_known = !is.na(staff_rangers)) %>%
  ggplot() +
    aes(y = PA_area, x = rangers_known) +
    ggbeeswarm::geom_quasirandom() +
    coord_trans(y = "log1p") +
    scale_y_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
    theme_minimal()
```

That is quite a good situation since no country with a huge PA_area has an unknown number of rangers.
We do miss rangers info for countries with very little PA_area so predictions for those countries will not be reliable, but based on the relationship we characterised such countries will have a negligible contribution to the total, so that is not an issue.

#### Using the distribution of the ratio

We have estimated before that the ratio which yields the coefficient of allometry can be considered as drawn from a normal distribution with a certain mean and variance.

A first simple methods to predict the number of rangers is thus to use such property to compute predictions for the number of rangers in the countries we did observe:

```{r simu1}
draw_rangers_from_raw_allo <- function(PA_area) {
  allo <- rnorm(n = length(PA_area),
        mean = mean(log(data_rangers_clean_noG$staff_rangers + 1) / log(data_rangers_clean_noG$PA_area), na.rm = TRUE),
        sd = sd(log(data_rangers_clean_noG$staff_rangers + 1) / log(data_rangers_clean_noG$PA_area), na.rm = TRUE))
  exp(allo * log(PA_area)) - 1
}
```

```{r plot simu1, fig.height=6, fig.width=6, cache=TRUE}
set.seed(1)
simu1 <- replicate(10000, sum(draw_rangers_from_raw_allo(data_rangers_clean_noG$PA_area[!is.na(data_rangers_clean_noG$staff_rangers)])))

res_simu1 <- tibble(x = simu1, 
  x_bin = round(simu1 / 20000) * 20000,
  x_obs = sum(data_rangers$staff_rangers, na.rm = TRUE),
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))

ggplot(res_simu1) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  geom_vline(xintercept = sum(data_rangers$staff_rangers, na.rm = TRUE), colour = "red", size = 1) +
  coord_cartesian(xlim = c(80000, 1000000)) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 100000), labels = seq(0, 1e6, by = 100000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  labs(fill = "Within 95%", x = "Total number of rangers across observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

As you can see the distribution encompasses well the observed sum (in red).

We can then do the same to predict the sum of rangers across the countries we did not observe (PS: I am assuming that countries with a null PA_area won't have any ranger):

```{r plot simu2, fig.height=6, fig.width=6, cache=TRUE}
data_rangers_clean_noG %>%
  filter(is.na(staff_rangers) & PA_area > 0) %>%
  pull(PA_area) -> PA_area_for_pred

set.seed(1)
simu2 <- replicate(10000, sum(draw_rangers_from_raw_allo(PA_area_for_pred)))

res_simu2 <- tibble(x = simu2, 
  x_bin = round(x / 2000) * 2000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))

ggplot(res_simu2) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  coord_cartesian(xlim = c(1000, 100000)) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 10000), labels = seq(0, 1e6, by = 10000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  labs(fill = "Within 95%", x = "Total number of rangers across non-observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

Summing this last series of predictions to the total observed, we obtain the following estimation of the total number of rangers on the planet (nb: those numbers do include Greenland):

```{r total_rangers1}
tibble(mean = round(mean(simu2) + sum(data_rangers$staff_rangers, na.rm = TRUE)),
       lower = round(quantile(simu2, probs = 0.025) + sum(data_rangers$staff_rangers, na.rm = TRUE)),
       upper = round(quantile(simu2, probs = 0.975) + sum(data_rangers$staff_rangers, na.rm = TRUE))) %>%
  pivot_longer(everything(), names_to = "estimate") %>%
  gt()
```

We will use other methods to produce predictions, but this gives us a first benchmark.

We thus have an uncertainty of around `r format(round(quantile(simu2, probs = 0.975)[[1]] - quantile(simu2, probs = 0.025)[[1]]), scientific = FALSE)` rangers. Notice however that the interval for our prediction is not centred around the mean prediction, which implies that there is less uncertainty about the lowest possible number of rangers than about the highest possible one. Indeed, 50% of the simulation give a number of unknown rangers between 0 and `r format(round(quantile(simu2, probs = 0.5)[[1]]), scientific = FALSE)` while there is a long tail on the right of the distribution.

#### Using the linear model #3

Another way to simulate the non-observed number of rangers is to use the linear models we fitted to simulate new data.

We start with the model called *model 3* above.

As before, we start by predicting the number of rangers for the countries for which we know it to check that things are OK:

```{r simu3, cache=TRUE}
fit_allometry3_spaMM <- fitme(log(staff_rangers + 1) /  log(PA_area) ~ 1, data = data_rangers_clean_noG)
PA_are_for_pred <- data_rangers_clean_noG$PA_area[!is.na(data_rangers_clean_noG$staff_rangers)]

set.seed(1)
simu3 <- replicate(1000, sum(exp(simulate(fit_allometry3_spaMM,
                                          newdata = data.frame(PA_area = PA_are_for_pred),
                                          type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                          verbose = c(type = FALSE)) * log(PA_are_for_pred)) - 1))

res_simu3 <- tibble(x = simu3, 
  x_bin = round(x / 20000) * 20000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))
```

```{r plot simu3, fig.height=6, fig.width=6, cache=TRUE}
ggplot(res_simu3) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  geom_vline(xintercept = sum(data_rangers$staff_rangers, na.rm = TRUE), colour = "red", size = 1) +
  coord_cartesian(xlim = c(80000, 1000000)) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 100000), labels = seq(0, 1e6, by = 100000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  labs(fill = "Within 95%", x = "Total number of rangers across observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

We now proceeds to predict the non-observed number of rangers:

```{r simu4, cache=TRUE}
PA_are_for_pred_nonobs <- data_rangers_clean_noG$PA_area[is.na(data_rangers_clean_noG$staff_rangers) & data_rangers_clean_noG$PA_area > 0]

set.seed(1)
simu4 <- replicate(1000, sum(exp(simulate(fit_allometry3_spaMM, newdata = data.frame(PA_area = PA_are_for_pred_nonobs),
                                          type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                          verbose = c(type = FALSE)) * log(PA_are_for_pred_nonobs)) - 1))

res_simu4 <- tibble(x = simu4, 
  x_bin = round(x / 2000) * 2000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))
```

```{r plot simu4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(res_simu4) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  coord_cartesian(xlim = c(1000, 100000)) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 10000), labels = seq(0, 1e6, by = 10000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  labs(fill = "Within 95%", x = "Total number of rangers across non-observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

Summing this last series of predictions to the total observed, we obtain the following estimation of the total number of rangers on the planet (nb: those numbers do include Greenland):

```{r total_rangers2}
tibble(mean = round(mean(simu4) + sum(data_rangers$staff_rangers, na.rm = TRUE)),
       lower = round(quantile(simu4, probs = 0.025) + sum(data_rangers$staff_rangers, na.rm = TRUE)),
       upper = round(quantile(simu4, probs = 0.975) + sum(data_rangers$staff_rangers, na.rm = TRUE))) %>%
  pivot_longer(everything(), names_to = "estimate") %>%
  gt()
```

**Conclusion**: the LM approach (using model 3) and the ad-hoc approach are equivalent.

#### Using the simple linear model #2

We now turn to the model called *model 2* above (i.e our best model so far).

As before, we start by predicting the number of rangers for the countries for which we know it to check that things are OK:

```{r simu5, cache=TRUE}
fit_allometry5_spaMM <- fitme(log(staff_rangers + 1)  ~ log(PA_area) - 1, data = data_rangers_clean_noG)

set.seed(1)
simu5 <- replicate(1000, sum(exp(simulate(fit_allometry5_spaMM,
                                          newdata = data.frame(PA_area = PA_are_for_pred),
                                          type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                          verbose = c(type = FALSE))) - 1))

res_simu5 <- tibble(x = simu5, 
  x_bin = round(x / 20000) * 20000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))
```

```{r plot simu5, fig.height=6, fig.width=6, cache=TRUE}
ggplot(res_simu5) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  geom_vline(xintercept = sum(data_rangers$staff_rangers, na.rm = TRUE), colour = "red", size = 1) +
  coord_cartesian(xlim = c(80000, 1000000)) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 100000), labels = seq(0, 1e6, by = 100000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  labs(fill = "Within 95%", x = "Total number of rangers across observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

We now proceeds to predict the non-observed number of rangers:

```{r simu6, cache=TRUE}
set.seed(1)
simu6 <- replicate(1000, sum(exp(simulate(fit_allometry5_spaMM, newdata = data.frame(PA_area = PA_are_for_pred_nonobs),
                                          type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                          verbose = c(type = FALSE))) - 1))

res_simu6 <- tibble(x = simu6, 
  x_bin = round(x / 2000) * 2000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))
```

```{r plot simu6, fig.height=6, fig.width=6, cache=TRUE}
ggplot(res_simu6) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  coord_cartesian(xlim = c(1000, 100000)) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 10000), labels = seq(0, 1e6, by = 10000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  labs(fill = "Within 95%", x = "Total number of rangers across non-observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

Summing this last series of predictions to the total observed, we obtain the following estimation of the total number of rangers on the planet (nb: those numbers do include Greenland):

```{r total_rangers3}
tibble(mean = round(mean(simu6) + sum(data_rangers$staff_rangers, na.rm = TRUE)),
       lower = round(quantile(simu6, probs = 0.025) + sum(data_rangers$staff_rangers, na.rm = TRUE)),
       upper = round(quantile(simu6, probs = 0.975) + sum(data_rangers$staff_rangers, na.rm = TRUE))) %>%
  pivot_longer(everything(), names_to = "estimate") %>%
  gt()
```

**Conclusion**: the LM approach using *model 2* produces estimates considerably narrower than the first 2 approaches we attempted. This is logical since it is our best model.

**Open question**: should fits be REML fits? (seems to enlarge distribution very slightly)


## Using additional predictors

A possible way to check if additional predictors may help is to see how they may shape the main relationship documented above.

For example, the population density look promising as you can see a positive relationship between our ratio and the predictor:

```{r popdensity_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = pop_density, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

In contrast the national GDP does not seem to exert any particular influence:

```{r GDP_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = GDP_2019, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

Nor does the GDP per capita:

```{r GDP_cap_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = GDP_capita, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

Or any of the ecological indices:

```{r EVI_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = EVI, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

```{r SPI_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = SPI, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

```{r EPI_PA_total plot4, fig.height=6, fig.width=6, cache=TRUE}
ggplot(data_rangers_clean_noG) +
  aes(y = log(staff_rangers + 1) / log(PA_area), x = EPI_2020, label = countryname_iso, colour = country_UN_continent) +
  geom_text() +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +
  scale_colour_discrete(guide = "none") +
  theme_minimal()
```

### Using population density

Let's first check for which country/territories we have no knowledge of the number of rangers and no estimate for the population density:
```{r pop density, rows.print=40}
data_rangers_clean %>%
  filter(is.na(pop_density), !is.na(staff_rangers)) %>%
  select(country, PA_area) %>%
  arrange(desc(PA_area)) %>%
  gt()
```

I think that the top 3 should be our priority since they have large area and "Svalbard and Jan Mayen" probably has very low density.

Let's also check where countries with no rangers information are compared to countries with information in view of population density:

```{r pop density explo, fig.height=6, fig.width=6, cache=TRUE}
# data_rangers_clean %>%
#   filter(!is.na(staff_rangers)) %>%
#   ggplot() +
#     aes(x = pop_density) +
#     stat_bin(binwidth = 100, geom = "bar", fill = NA, colour = "black") +
#     geom_rug(data = data_rangers_clean %>% filter(is.na(staff_rangers)), colour = "orange") +
#     theme_minimal()

data_rangers_clean %>%
  mutate(rangers_known = !is.na(staff_rangers)) %>%
  ggplot() +
    aes(y = pop_density, x = rangers_known) +
    ggbeeswarm::geom_quasirandom() +
    coord_trans(y = "log") +
    scale_y_continuous(breaks = 10^(0:7), minor_breaks = NULL) +
    theme_minimal()
```

That does not look very good because extreme population densities are only found in countries for which we have no ranger info.
In other words, predicting rangers for such countries will correspond to extrapolation.

But, let us look at the problematic countries (i.e those corresponding to extrapolation):

```{r pb countries}
data_rangers_clean %>%
  filter(is.na(staff_rangers),
         pop_density > max(data_rangers_clean %>%
                             filter(!is.na(staff_rangers)) %>%
                             pull(pop_density), na.rm = TRUE)) %>%
  arrange(desc(pop_density)) %>%
  select(country, pop_density, PA_area) %>%
  gt()
```

OK, they contain very few PA area so that should not be an issue!

Let's fit the following model to include the population density:

$\mathrm{log}(\mathrm{staff\_rangers} + 1) = a \times \mathrm{log}(\mathrm{PA\_area}) + b \times \mathrm{log}(\mathrm{pop\_density}) + c$

```{r lm pop density}
fit_pop <- lm(log(staff_rangers + 1) ~ log(PA_area) + log(pop_density), data = data_rangers_clean_noG)
tidy(summary(fit_pop)) %>%
  mutate(across(where(is.numeric), .fns = round, digits = 3)) %>%
  gt()
```

Again, you can see a allometry coefficient lower than one, which implies that the number of rangers increases less quickly than population density.

Let's check if the assumption for linear modelling are fulfilled:

```{r plot fit_pop fit, fig.height=10, fig.width=10, cache=TRUE}
par(mfrow = c(2, 2))
plot(fit_pop)
```


```{r lm pop density vs model 2}
refit_model2 <- lm(log(staff_rangers + 1) ~ log(PA_area) - 1, data = data_rangers_clean_noG[!is.na(data_rangers_clean_noG$pop_density), ])
```

This looks very good. The AIC of this new model (`r round(AIC(fit_pop), digits = 1)`) is also considerably better than the AIC of our model 2 refitted on the same data (`r round(AIC(refit_model2), digits = 1)`), so accounting for population density is a considerable improvement!

We can now predict the number of rangers using this new model and here it gets a little bit more complex than before because we have to add:

- the number of rangers that are known
- the predictions for the number of rangers from model 2 for the countries for which we have no population density
- the predictions for the number of rangers from the new model for the countries for which we do have population density

Here is the result for our estimation of the total number of rangers:

```{r prediction with density pop, cache=TRUE}
fit_allometry6_spaMM <- fitme(log(staff_rangers + 1) ~ log(PA_area) + log(pop_density), data = data_rangers_clean_noG)

rangers_known <- sum(data_rangers_clean$staff_rangers, na.rm = TRUE)

data_rangers_clean %>%
  filter(is.na(staff_rangers),
         is.na(pop_density),
         PA_area > 0) -> data_no_pop_size

data_rangers_clean %>%
  filter(is.na(staff_rangers),
         !is.na(pop_density),
         PA_area > 0) -> data_with_pop_size

set.seed(1)
simu7 <- replicate(1000, {
  rangers_predicted_no_pop_size <- sum(exp(simulate(fit_allometry5_spaMM,
                                                newdata = data.frame(PA_area = data_no_pop_size$PA_area),
                                                type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                                verbose = c(type = FALSE))) - 1)
  
  rangers_predicted_with_pop_size <- sum(exp(simulate(fit_allometry6_spaMM,
                                                  newdata = data.frame(PA_area =  data_with_pop_size$PA_area,
                                                                       pop_density = data_with_pop_size$pop_density),
                                                type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                                verbose = c(type = FALSE))) - 1)
  rangers_known + rangers_predicted_no_pop_size + rangers_predicted_with_pop_size
})

res_simu7 <- tibble(x = simu7, 
  x_bin = round(x / 2000) * 2000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))
```

```{r total_rangers4, cache=TRUE}
tibble(mean = round(mean(simu7)),
       lower = round(quantile(simu7, probs = 0.025)),
       upper = round(quantile(simu7, probs = 0.975))) %>%
  pivot_longer(everything(), names_to = "estimate") %>%
  gt()
```

So we have reduced the uncertainty, although not by a huge amount

### Accounting for spatial autocorrelation

We will now consider the case of spatial autocorrelation.
Its consideration may help predict the number of rangers.

First we need to get the latitudes and longitudes for the different countries/territories.
I did this above in the step called "Data preparation" using the package **{rnaturalearth}**.

Since the package gives polygons defining the countries/territories, I chose to pick the centroid of the largest polygons.

That failed for the following countries/territories:

```{r getting coordinates, messsage=FALSE}
data_rangers_clean %>% 
  filter(is.na(long) | is.na(lat)) %>%
  select(country, PA_area, staff_rangers) %>%
  gt()
```

We could fix this, but for now I will stick to what we have.

(Note to self: I have already fixed one country whose ISO code was missing (Norway).)

Let us refit the model that does not account for the population density accounting for the spatial autocorrelation.

```{r matern 1, cache=TRUE}
data_rangers_clean_noG %>%
  drop_na(staff_rangers, PA_area, long, lat) -> data_for_matern_no_pop

fit_matern_no_pop <- fitme(log(staff_rangers + 1) ~ 0 + log(PA_area) + Matern(1|long + lat), data = data_for_matern_no_pop,
                           control.dist = list(dist.method = "Earth"))
fit_no_matern_no_pop <- fitme(log(staff_rangers + 1) ~ 0 + log(PA_area), data = data_for_matern_no_pop,
                              control.dist = list(dist.method = "Earth"))
```

The model is better than the one not accounting for the spatial autocorrelation (AIC with autocorrelation = `r round(AIC(fit_matern_no_pop)[2][[1]], digits = 1)`; AIC without = `r round(AIC(fit_no_matern_no_pop)[[1]], digits = 1)`, on the same data!).

We also refit the model that does account for the population density accounting for the spatial autocorrelation.

```{r matern 2, cache=TRUE}
data_rangers_clean_noG %>%
  drop_na(staff_rangers, PA_area, long, lat, pop_density) -> data_for_matern_pop

fit_matern_pop <- fitme(log(staff_rangers + 1) ~ 1 + log(PA_area) + log(pop_density) + Matern(1|long + lat), data = data_for_matern_pop,
                           control.dist = list(dist.method = "Earth"))
fit_no_matern_pop <- fitme(log(staff_rangers + 1) ~ 1 + log(PA_area) + log(pop_density), data = data_for_matern_pop,
                              control.dist = list(dist.method = "Earth"))
```

The model is better than the one not accounting for the spatial autocorrelation (AIC with autocorrelation = `r round(AIC(fit_matern_pop)[2][[1]], digits = 1)`; AIC without = `r round(AIC(fit_no_matern_pop)[[1]], digits = 1)`, on the same data!).

Let's now predict the sum for rangers for the countries for which we know it (as a test that the simulations work) using the model accounting for the population density:

```{r test simu Matern, cache=TRUE}
set.seed(1)
simu8 <- replicate(1000, {
  sum(exp(simulate(fit_no_matern_pop,
                   newdata = data.frame(PA_area = data_for_matern_pop$PA_area, pop_density = data_for_matern_pop$pop_density),
                   type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                   verbose = c(type = FALSE))) - 1)})

res_simu8 <- tibble(x = simu8, 
  x_bin = round(simu8 / 20000) * 20000,
  x_obs = sum(data_for_matern_pop$staff_rangers, na.rm = TRUE),
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))

ggplot(res_simu8) +
  aes(x = x_bin, fill = filled) +
  geom_bar() +
  geom_vline(xintercept = sum(data_for_matern_pop$staff_rangers, na.rm = TRUE), colour = "red", size = 1) +
  coord_cartesian(xlim = c(0, 4e5)) +
  scale_x_continuous(breaks = seq(0, 1e6, by = 100000), labels = seq(0, 1e6, by = 100000), minor_breaks = NULL) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_fill_manual(values = c("darkgreen", "orange")) +
  labs(fill = "Within 95%", x = "Total number of rangers across observed countries", y = "Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))
```

This seems to work, so we can now predict the number of rangers using this new models and complexity keeps increasing as we now need to add:

- the number of rangers that are known: `r data_rangers_clean %>% filter(!is.na(staff_rangers)) %>% pull(flag)`
- the predictions for the number of rangers from the model accounting for PA_area and spatial autocorrelation for the countries for which we have no population density but lat and long: `r data_rangers_clean %>% filter(is.na(staff_rangers), is.na(pop_density), !is.na(lat)) %>% pull(flag)`
- the predictions for the number of rangers from the model accounting for PA_area and not considering spatial autocorrelation for the countries for which we have no population density, nor lat or long: `r data_rangers_clean %>% filter(is.na(staff_rangers), is.na(pop_density), is.na(lat)) %>% pull(flag)`
- the predictions for the number of rangers from the model accounting for PA_area, pop_density and spatial autocorrelation for the countries for which we do have population density and lat and long: `r data_rangers_clean %>% filter(is.na(staff_rangers), !is.na(pop_density), !is.na(lat)) %>% pull(flag)`
- the predictions for the number of rangers from the model accounting for PA_area, pop_density and not considering spatial autocorrelation for the countries for which we do have population density but not lat or long: `r data_rangers_clean %>% filter(is.na(staff_rangers), !is.na(pop_density), is.na(lat)) %>% pull(flag)` (there aren't any in practice)

Here is the result for our estimation of the total number of rangers:

```{r prediction with density pop and Matern, cache=TRUE}
rangers_known <- sum(data_rangers_clean$staff_rangers, na.rm = TRUE)

data_rangers_clean %>%
  filter(is.na(staff_rangers),
         is.na(pop_density),
         is.na(lat),
         PA_area > 0) -> data_no_pop_size_no_coord

data_rangers_clean %>%
  filter(is.na(staff_rangers),
         is.na(pop_density),
         !is.na(lat),
         PA_area > 0) -> data_no_pop_size_coord

# data_rangers_clean %>% # does not happen!
#   filter(is.na(staff_rangers),
#          !is.na(pop_density),
#          is.na(lat),
#          PA_area > 0) -> data_with_pop_size_no_coord

data_rangers_clean %>%
  filter(is.na(staff_rangers),
         !is.na(pop_density),
         !is.na(lat),
         PA_area > 0) -> data_with_pop_size_coord

set.seed(1)
simu9 <- replicate(1000, {
  rangers_predicted_no_pop_size_no_coord <- sum(exp(simulate(fit_allometry5_spaMM,
                                                newdata = data.frame(PA_area = data_no_pop_size_no_coord$PA_area),
                                                type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                                verbose = c(type = FALSE))) - 1)
  
  rangers_predicted_no_pop_size_coord <- sum(exp(simulate(fit_matern_no_pop,
                                                newdata = data.frame(PA_area = data_no_pop_size_coord$PA_area,
                                                                     lat = data_no_pop_size_coord$lat,
                                                                     long = data_no_pop_size_coord$long), 
                                                type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                                verbose = c(type = FALSE))) - 1)
  
  rangers_predicted_pop_size_coord <- sum(exp(simulate(fit_matern_pop,
                                              newdata = data.frame(PA_area =  data_with_pop_size_coord$PA_area,
                                                                   pop_density = data_with_pop_size_coord$pop_density,
                                                                   lat = data_with_pop_size_coord$lat,
                                                                   long = data_with_pop_size_coord$long),
                                              type = "predVar", variances = list(linPred = TRUE, disp = TRUE),
                                              verbose = c(type = FALSE))) - 1)
  
  rangers_known + rangers_predicted_no_pop_size_no_coord + rangers_predicted_no_pop_size_coord + rangers_predicted_pop_size_coord
})

res_simu9 <- tibble(x = simu9, 
  x_bin = round(x / 2000) * 2000,
  lower = quantile(x, probs = 0.025),
  upper = quantile(x, probs = 0.975),
  filled = factor(if_else(x > lower & x < upper, "in", "out")))
```

```{r total_rangers9, cache=TRUE}
tibble(mean = round(mean(simu9)),
       lower = round(quantile(simu9, probs = 0.025)),
       upper = round(quantile(simu9, probs = 0.975))) %>%
  pivot_longer(everything(), names_to = "estimate") %>%
  gt()
```
